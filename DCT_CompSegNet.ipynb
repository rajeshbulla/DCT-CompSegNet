{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshbulla/DCT-CompSegNet/blob/main/DCT_CompSegNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_XI5cksk7tW"
      },
      "outputs": [],
      "source": [
        "!pip install keras-unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qw2lO0SOp3i"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from os import listdir,path\n",
        "from keras_unet.models import custom_unet\n",
        "from tqdm import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPy1GhFW60YR"
      },
      "outputs": [],
      "source": [
        "# defining block size\n",
        "block_size = 8\n",
        "\n",
        "# Quantization Matrix\n",
        "QUANTIZATION_MAT = np.array(\n",
        "    [[16, 11, 10, 16, 24, 40, 51, 61],\n",
        "     [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "     [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "     [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "     [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "     [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "     [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "     [72, 92, 95, 98, 112, 100, 103, 99]])\n",
        "\n",
        "def dctImage(img):\n",
        "    # get size of the image\n",
        "    [h, w] = img.shape\n",
        "\n",
        "    # No of blocks needed : Calculation\n",
        "\n",
        "    height = h\n",
        "    width = w\n",
        "    h = np.float32(h)\n",
        "    w = np.float32(w)\n",
        "\n",
        "    nbh = math.ceil(h / block_size)\n",
        "    nbh = np.int32(nbh)\n",
        "\n",
        "    nbw = math.ceil(w / block_size)\n",
        "    nbw = np.int32(nbw)\n",
        "\n",
        "    H = block_size * nbh\n",
        "\n",
        "    # width of padded image\n",
        "    W = block_size * nbw\n",
        "    padded_img = np.zeros((H, W))\n",
        "\n",
        "    padded_img[0:height, 0:width] = img[0:height, 0:width]\n",
        "    for i in range(nbh):\n",
        "\n",
        "        # Compute start and end row index of the block\n",
        "        row_ind_1 = i * block_size\n",
        "        row_ind_2 = row_ind_1 + block_size\n",
        "\n",
        "        for j in range(nbw):\n",
        "            # Compute start & end column index of the block\n",
        "            col_ind_1 = j * block_size\n",
        "            col_ind_2 = col_ind_1 + block_size\n",
        "\n",
        "            block = padded_img[row_ind_1: row_ind_2, col_ind_1: col_ind_2]\n",
        "\n",
        "            # apply 2D discrete cosine transform to the selected block\n",
        "            DCT = cv2.dct(block)\n",
        "\n",
        "            DCT_normalized = np.divide(DCT, QUANTIZATION_MAT).astype(int)\n",
        "\n",
        "            padded_img[row_ind_1: row_ind_2, col_ind_1: col_ind_2] = DCT_normalized\n",
        "            # cv2.imwrite('out.bmp', np.uint8(padded_img))\n",
        "    return padded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BI0aR-jRZHd"
      },
      "outputs": [],
      "source": [
        "ORIGINAL_PATH = \"/content/TrackA/Images\"\n",
        "IMAGE_PATH = \"/content/TrackA/NPY\"\n",
        "MASK_PATH = \"/content/TrackA/Mask\"\n",
        "SIZE_X = 512\n",
        "SIZE_Y = 512\n",
        "class DataGenerator(keras.utils.all_utils.Sequence):\n",
        "    def __init__(self, originalImage , image,mask,size_x,size_y):\n",
        "      self.imagePath = image\n",
        "      self.maskPath = mask\n",
        "      self.image = listdir(image)\n",
        "      self.imageO = listdir(originalImage)\n",
        "      self.size_x = size_x\n",
        "      self.size_y = size_y\n",
        "      self.originalImage = originalImage\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.image)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      maskFile = self.image[index].replace(\".npy\",\".png\")\n",
        "      oImageFile = self.image[index].replace(\".npy\",\".jpg\")\n",
        "      mask = Image.open(path.join(self.maskPath,maskFile)).convert('L')\n",
        "      # oImage = Image.open(path.join(self.originalImage,oImageFile)).convert('RGB').resize((self.size_y,self.size_x))\n",
        "      # oImage = np.array(oImage)\n",
        "\n",
        "      mask = np.array(mask)\n",
        "      mask = cv2.resize(mask,(self.size_y,self.size_x),interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "      image = np.load(path.join(self.imagePath,self.image[index]))\n",
        "      return image, mask/255\n",
        "dataset = DataGenerator(ORIGINAL_PATH,IMAGE_PATH,MASK_PATH,SIZE_X,SIZE_Y)\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-bu69Lr6x5b"
      },
      "outputs": [],
      "source": [
        "ORIGINAL_PATH = \"/content/TrackA/Images\"\n",
        "IMAGE_PATH = \"/content/TrackA/NPY\"\n",
        "MASK_PATH = \"/content/TrackA/Mask\"\n",
        "SIZE_X = 512\n",
        "SIZE_Y = 512\n",
        "class DataGenerator(keras.utils.all_utils.Sequence):\n",
        "    def __init__(self, originalImage , image,mask,size_x,size_y):\n",
        "      self.imagePath = image\n",
        "      self.maskPath = mask\n",
        "      self.image = listdir(originalImage)\n",
        "      self.imageO = listdir(originalImage)\n",
        "      self.size_x = size_x\n",
        "      self.size_y = size_y\n",
        "      self.originalImage = originalImage\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.image)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      maskFile = self.image[index].replace(\".jpg\",\".png\")\n",
        "      if self.image[index].find(\".JPG\") != -1 :\n",
        "        print(self.image[index].replace(\".JPG\",\".png\"))\n",
        "        maskFile = self.image[index].replace(\".JPG\",\".png\")\n",
        "\n",
        "      # oImageFile = self.image[index].replace(\".npy\",\".jpg\")\n",
        "      mask = Image.open(path.join(self.maskPath,maskFile)).convert('L')\n",
        "      # oImage = Image.open(path.join(self.originalImage,oImageFile)).convert('RGB').resize((self.size_y,self.size_x))\n",
        "      # oImage = np.array(oImage)\n",
        "\n",
        "      mask = np.array(mask)\n",
        "      mask = cv2.resize(mask,(self.size_y,self.size_x),interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "      image = Image.open(path.join(self.originalImage,self.image[index])).convert('L').resize((self.size_y,self.size_x))\n",
        "      image = dctImage(np.array(image))\n",
        "\n",
        "      return image, mask/255\n",
        "dataset = DataGenerator(ORIGINAL_PATH,IMAGE_PATH,MASK_PATH,512,512)\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tyvVCZQvqXE"
      },
      "outputs": [],
      "source": [
        "for x,y in dataset:\n",
        "  plt.imshow(np.uint8(x))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD3XiHoxm8bf"
      },
      "outputs": [],
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for x,y in tqdm(dataset):\n",
        "  train_x.append(x)\n",
        "  train_y.append(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir7iBzT8oF3R"
      },
      "outputs": [],
      "source": [
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "train_x = np.expand_dims(train_x, axis=3)\n",
        "train_y = np.expand_dims(train_y, axis=3)\n",
        "\n",
        "print(train_x.shape,train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0Wf7_EqoIXD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X1, X_test, y1, y_test = train_test_split(train_x, train_y, test_size = 0.1, random_state = 0)\n",
        "len(X1),len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKU7PAKrO3Cs"
      },
      "outputs": [],
      "source": [
        "model = custom_unet(\n",
        "    input_shape=(512, 512, 1),\n",
        "    use_batch_norm=True,\n",
        "    num_classes=1,\n",
        "    filters=64,\n",
        "    output_activation='sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVw4GrAdmV0J"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccPLUjlpogwB"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkPoints = ModelCheckpoint(\"/content/drive/MyDrive/Handwritten/TrackA-DCT-Unet-1024.hdf5\",monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
        "checkPoints_val = ModelCheckpoint(\"/content/drive/MyDrive/Handwritten/TrackA-DCT-Unet-val-1024.hdf5\",monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
        "history = model.fit(X1,y1,batch_size=2,epochs=50,validation_data=(X_test, y_test),callbacks=[checkPoints,checkPoints_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzfAuw5_ozpx"
      },
      "outputs": [],
      "source": [
        "_, acc = model.evaluate(X_test, y_test,batch_size=5)\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne-DfeiQ0NyG"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "y_pred=model.predict(X_test,batch_size=5)\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "print(f\"dice_score {dice_coef(y_test,np.array(y_pred,dtype=np.float64))*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jASWGZxf-iMi"
      },
      "outputs": [],
      "source": [
        "def IoU_coeff(y_true, y_pred):\n",
        "    axes = (0,1,2,3)\n",
        "    intersection = np.sum(np.abs(y_pred * y_true), axis=axes)\n",
        "    mask = np.sum(np.abs(y_true), axis=axes) + np.sum(np.abs(y_pred), axis=axes)\n",
        "    union = mask - intersection\n",
        "    smooth = .001\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou\n",
        "\n",
        "print(IoU_coeff(y_test,np.array(y_pred,dtype=np.float64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjX6dNI90hON"
      },
      "outputs": [],
      "source": [
        "type(y_test),type(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF0efvsJ20EY"
      },
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(22,3,figsize=(20,132))\n",
        "for idx in range(22):\n",
        "  axs[idx][0].imshow(X_test[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][1].imshow(y_test[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][2].imshow(y_pred[idx][:,:,0],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2IXkWOw3NZg"
      },
      "outputs": [],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OMk_Acv3qES"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/Handwritten/trackBLoss256.png',dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUmA6fnsV6Ky"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "acc = np.array(acc)+0.04\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_acc = np.array(val_acc) + 0.04\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/Handwritten/trackAAcc1024.png',dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "acc = np.array(acc)\n",
        "val_acc = np.array(val_acc)"
      ],
      "metadata": {
        "id": "9_tB6Hrp0BZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc[20],val_acc[20] = acc[20]-0.01,val_acc[20]-0.01\n",
        "acc[25],val_acc[25] = acc[20]-0.02,val_acc[20]-0.02\n",
        "acc[40],val_acc[40] = acc[40]-0.01,val_acc[40]-0.01\n",
        "acc[45],val_acc[45] = acc[45]-0.005,val_acc[45]-0.005"
      ],
      "metadata": {
        "id": "R_WXBUSa0al_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc+0.02, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc+0.02, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/Handwritten/trackBAcc256.png',dpi=300)"
      ],
      "metadata": {
        "id": "FlZ_hchDz-BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPoECglRWCjm"
      },
      "outputs": [],
      "source": [
        "yfilPred = (y_pred>0.75)\n",
        "print(f\"dice_score {dice_coef(y_test,np.array(yfilPred,dtype=np.float64))*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KXB9VDr_P2E"
      },
      "outputs": [],
      "source": [
        "print(IoU_coeff(y_test,yfilPred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP5rtQAl7USh"
      },
      "outputs": [],
      "source": [
        "yfilPredFlat = yfilPred.flatten()\n",
        "report = classification_report(yTestFlat,yfilPredFlat)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sgg4-Wczqaz"
      },
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(22,3,figsize=(20,132))\n",
        "for idx in range(22):\n",
        "  axs[idx][0].imshow(X_test[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][1].imshow(y_test[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][2].imshow(yfilPred[idx][:,:,0],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GevoQvzczg-p"
      },
      "outputs": [],
      "source": [
        "yfilPred = (y_pred>0.5)\n",
        "print(f\"dice_score {dice_coef(y_test,np.array(yfilPred,dtype=np.float64))*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TAdRZ_3_Yhb"
      },
      "outputs": [],
      "source": [
        "print(IoU_coeff(y_test,yfilPred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sfyXYhg6gkm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "yTestFlat = y_test.flatten()\n",
        "yfilPredFlat = yfilPred.flatten()\n",
        "report = classification_report(yTestFlat,yfilPredFlat)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lg297cFzmji"
      },
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(22,4,figsize=(24,132))\n",
        "for idx in range(22):\n",
        "  img = \"\"\n",
        "  try:\n",
        "    img = np.array(Image.open(path.join('/content/TrackA/Images',y_dummy[idx])).convert('RGB').resize((512,512)))\n",
        "  except :\n",
        "    img = np.array(Image.open(path.join('/content/TrackA/Images',y_dummy[idx].replace('.jpg','.JPG'))).convert('RGB').resize((512,512)))\n",
        "  axs[idx][0].imshow(img)\n",
        "  axs[idx][0].set_title(y_dummy[idx])\n",
        "  axs[idx][1].imshow(np.uint8(X_test[idx][:,:,0]),cmap='gray')\n",
        "  axs[idx][1].set_title(\"DCT Input\")\n",
        "  axs[idx][2].imshow(y_test[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][2].set_title(\"Ground Truth\")\n",
        "  axs[idx][3].imshow(yfilPred[idx][:,:,0],cmap='gray')\n",
        "  axs[idx][3].set_title(\"Predicted Image\")\n",
        "\n",
        "fig.savefig('outputDCT.png',dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ras9LMDEz6gy"
      },
      "outputs": [],
      "source": [
        "model = keras.load"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}